{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0+XwxLFGEhF7IubVkH2+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoshiki0418/Deep_Learning/blob/main/Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoGrad"
      ],
      "metadata": {
        "id": "TpXDtqueGekA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorchでは計算グラフを自動的に構築し、勾配を逆方向に計算することができる。tensor生成時に、`requires_grad=True`を設定することで自動微分を有効にすることができる。計算後に、`.backward`を呼ぶことで自動的に勾配が計算される。\n",
        "\n",
        "勾配情報は、`.grad`属性に累積されるが、末端ノードに対する勾配しか保存されない。中間ノードに対する勾配を保存したい場合は、当該tensorに対して、`.retain_grad()`を実行する必要がある。"
      ],
      "metadata": {
        "id": "Js_9Yw-5GiWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PythonでAutoGradを試してみる"
      ],
      "metadata": {
        "id": "tNNHLefRGtBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "今回は以下の式の勾配をAutoGradを使って求める。\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\n",
        "初期のtensorの値：x=2,  y=3\n",
        "$$\n",
        "\n",
        "$$\n",
        "z = y×log(x) + sin(y)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{∂z}{∂a}　及び　\\frac{∂z}{∂y}を求める\n",
        "$$"
      ],
      "metadata": {
        "id": "w6A-wr9fGxOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg36_IbSGTee",
        "outputId": "7e516dbd-0fba-4106-fd94-2625e3029597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2206, grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import tensor\n",
        "\n",
        "x = tensor(2. , requires_grad=True)\n",
        "y = tensor(3. , requires_grad=True)\n",
        "\n",
        "z = y * torch.log(x) + torch.sin(y)\n",
        "\n",
        "print(z)\n",
        "z.backward()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFf2727pI2Du",
        "outputId": "2800de68-fa88-4788-a93e-5262b3515edf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.5000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft6Pn1l6Jn7e",
        "outputId": "21a30e32-a7d4-4aa2-cb24-2a6f675ac3b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.2968)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 累積されていくことをもう一度実行することによって確認する\n",
        "z = y * torch.log(x) + torch.sin(y)\n",
        "z.backward()"
      ],
      "metadata": {
        "id": "GI0v9MUuJoyj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPKDWDNXKFun",
        "outputId": "2227ad16-cab8-4d7d-94b5-543811831491"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygElDrljKGwB",
        "outputId": "64863a54-dfe2-484b-be5a-a19505da1d26"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8905)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AutoGradで勾配を計算する(中間ノードの勾配)"
      ],
      "metadata": {
        "id": "d-oC2k3HKzrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "勾配情報は、末端ノードのみが累積によって保存されていくことを学んだ。しかし、中間ノードを確認したい場合もある。そこで、中間ノードに対する勾配を保存したい場合は、当該tensorに対して、.retain_grad()を実行する。\n",
        "\n",
        "* 以下の式の勾配をAutogradで求める\n",
        "$$\n",
        "初期のtensorの値：x=2,  y=3\n",
        "$$\n",
        "\n",
        "$$\n",
        "z = (x + y)^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "中間ノードとなる\\frac{∂z}{∂(x + y)}を求める\n",
        "$$"
      ],
      "metadata": {
        "id": "zTDc2O1SLGT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tensor(2. , requires_grad=True)\n",
        "y = tensor(3. , requires_grad=True)\n",
        "\n",
        "# u を x と y の合計として定義し、後で勾配を取得するために勾配保持を有効にする\n",
        "u = x + y\n",
        "u.retain_grad()\n",
        "\n",
        "z = u ** 2\n",
        "\n",
        "print(z)\n",
        "z.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on8YfviBKWcw",
        "outputId": "5b490d9b-7303-4473-c90e-423370ea7591"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(25., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRAhfwQaMeaf",
        "outputId": "3766df0d-823b-4e0b-9c45-d8dc7adf5b51"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogDrnJjuM3oA",
        "outputId": "add6ac56-fd0f-472f-af76-ee2ecefca589"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrU29VWeNWL7",
        "outputId": "243ebd8b-bf42-4a75-9d91-a3efdda86568"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 勾配を保持する必要がない場合"
      ],
      "metadata": {
        "id": "tSK-2DCOOYrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autogradで勾配を保持するには、計算グラフを構築するため、計算量が高くなりメモリ使用量も増える。したがって、勾配を計算する必要がないケースでは、`with torch.no_grad():`を使って勾配を計算しないようにすることで、計算速度が向上し、メモリ使用量が減少する。\n",
        "\n",
        "<br>\n",
        "\n",
        "では、どのような場面で使用することがあるのか？\n",
        "\n",
        "→モデルの推論(予測)時やパラメータの更新時に使用する。"
      ],
      "metadata": {
        "id": "7xSboRR0OdGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tensor(2. , requires_grad=True)\n",
        "y = tensor(3. , requires_grad=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = y * torch.log(x) + torch.sin(y)\n",
        "  print(z)\n",
        "\n",
        "t = y * torch.log(x) + torch.sin(y)\n",
        "print(t)\n",
        "\n",
        "# z.backward(). => torch.no_grad():内で計算しているので、勾配が計算されていないので使用することができない\n",
        "t.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAcKcQhYOcJh",
        "outputId": "eed02500-af32-4dc1-f93c-7573b5ba3751"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2206)\n",
            "tensor(2.2206, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}