{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJT6dUebB18iWf8FXJiVYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoshiki0418/Deep_Learning/blob/main/DL_Lecture3/gate_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ゲート付きRNN"
      ],
      "metadata": {
        "id": "0Bl_EpzMNZAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UGRNN"
      ],
      "metadata": {
        "id": "NL-Yi9WuNbqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "18B-hn69NTlX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class UGRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # 線形変換\n",
        "        self.transform = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.update_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "\n",
        "        # 活性化関数\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, input, h_0=None):\n",
        "        # input: [batch_size, seq_len, input_size]\n",
        "        # seq_len: 各サンプルに含まれる単語やトークンの数（つまり、シーケンスの長さ）。\n",
        "        # input_size: 各単語ベクトルの次元数（単語埋め込みのサイズ）。\n",
        "        batch_size, self.seq_len, _ = input.size()\n",
        "\n",
        "        if h_0 is None:\n",
        "            h_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
        "\n",
        "        h = h_0.squeeze(0) # [1, batch_size, hidden_size] -> [batch_size, hidden_size]\n",
        "        outputs = []\n",
        "        for i in range(self.seq_len):\n",
        "            # [batch_size, hidden_size]\n",
        "            # h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h)\n",
        "            combined = torch.cat((input[:, i, :], h), dim=1)\n",
        "            hidden_candidate = self.tanh(self.transform(combined))\n",
        "            update_gate = self.sigmoid(self.update_gate(combined))\n",
        "            h = update_gate * hidden_candidate + (1-update_gate) * h\n",
        "            outputs.append(h.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
        "        self.output_seq = torch.cat(outputs, dim=1)\n",
        "        h_n = h.unsqueeze(0) # [batch_size, hidden_size] -> [1, batch_size, hidden_size]\n",
        "\n",
        "        return self.output_seq, h_n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# UGRNNのテスト\n",
        "input_size = 10\n",
        "hidden_size = 3\n",
        "batch_size = 8\n",
        "seq_len = 5\n",
        "\n",
        "# サンプルのTensor\n",
        "input_tensor = torch.randn(batch_size, seq_len, input_size)"
      ],
      "metadata": {
        "id": "eJnjRaTkSJFJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ugrnn = UGRNN(input_size, hidden_size)\n",
        "output_seq, h_n = ugrnn(input_tensor)"
      ],
      "metadata": {
        "id": "qrYvcRNgSkIM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3VwEo4JS3bR",
        "outputId": "969f44e9-947b-4948-861d-45cb917d6eea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_n.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fzxBJ8YS7Nr",
        "outputId": "fc1debdf-028b-4e49-f7bc-576287a26664"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "5wIdnevbfXX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # ゲート\n",
        "        self.update_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.forget_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.output_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "\n",
        "        # セル状態の更新に必要な全結合層\n",
        "        self.cell_candidate = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "\n",
        "        # 活性化関数\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, input, h_0=None, c_0=None):\n",
        "        # input: [batch_size, seq_len, input_size]\n",
        "        batch_size, self.seq_len, _ = input.size()\n",
        "\n",
        "        if h_0 is None:\n",
        "            h_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
        "        if c_0 is None:\n",
        "            c_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
        "\n",
        "        h = h_0.squeeze(0) # [1, batch_size, hidden_size] -> [batch_size, hidden_size]\n",
        "        c = c_0.squeeze(0) # [1, batch_size, hidden_size] -> [batch_size, hidden_size]\n",
        "        outputs = []\n",
        "        for i in range(self.seq_len):\n",
        "            # [batch_size, hidden_size]\n",
        "            # h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h)\n",
        "            combined = torch.cat((input[:, i, :], h), dim=1)\n",
        "            cell_candidate = self.tanh(self.cell_candidate(combined))\n",
        "\n",
        "            update_gate = self.sigmoid(self.update_gate(combined))\n",
        "            forget_gate = self.sigmoid(self.forget_gate(combined))\n",
        "            output_gate = self.sigmoid(self.output_gate(combined))\n",
        "\n",
        "            c = update_gate * cell_candidate + forget_gate * c\n",
        "            h = output_gate * self.tanh(c)\n",
        "\n",
        "            outputs.append(h.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
        "        self.output_seq = torch.cat(outputs, dim=1)\n",
        "        h_n = h.unsqueeze(0) # [batch_size, hidden_size] -> [1, batch_size, hidden_size]\n",
        "        c_n = c.unsqueeze(0) # [batch_size, hidden_size] -> [1, batch_size, hidden_size]\n",
        "\n",
        "        return self.output_seq, (h_n, c_n)"
      ],
      "metadata": {
        "id": "O3Ydso81fY0K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テスト\n",
        "lstm = myLSTM(input_size, hidden_size)\n",
        "output_seq, (h_n, c_n) = lstm(input_tensor)"
      ],
      "metadata": {
        "id": "TYe-YX4Pggpw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwfF81GWg3rM",
        "outputId": "5ba9a43c-d7d7-4a11-d582-b553b7294d32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_n.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o1_-Dwrg7-n",
        "outputId": "98a03d94-1827-487d-d863-13f603da728e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_n.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyYFD-FPg_b_",
        "outputId": "1bdefe47-c922-4b43-ae4b-99a20397be6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorchを使用したGRUとLSTM"
      ],
      "metadata": {
        "id": "fpT9pd9ZhDrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "output_seq, (h_n, c_n) = lstm(input_tensor)"
      ],
      "metadata": {
        "id": "3wIau0IbhGHq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tf3CRVrh5db",
        "outputId": "7f199541-b058-49ae-f01c-711d6bb5775c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h_n.shape, c_n.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bgW2inSh8VZ",
        "outputId": "c31056d6-a5d3-4ecf-803f-158b959e7ba8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 3]) torch.Size([1, 8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU\n",
        "gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "output_seq, h_n = gru(input_tensor)"
      ],
      "metadata": {
        "id": "NZG3qggqh_NB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_seq.shape, h_n.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ9RXjkUiBai",
        "outputId": "cc9e4a0c-45a9-4b13-a022-7f3c18e8008e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 5, 3]) torch.Size([1, 8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, rnn_type='LSTM'):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if rnn_type == 'RNN':\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'UGRNN':\n",
        "            self.rnn = UGRNN(input_size, hidden_size)\n",
        "        else:\n",
        "            raise ValueError('Unsupported RNN type. Choose from [\"LSTM\", \"RNN\", \"GRU\", \"UGRNN\"]')\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output_seq, _ = self.rnn(x)\n",
        "        # output_seq: [batch_size, seq_len, hidden_size]\n",
        "        # h_n: [1, batch_size, hidden_size]\n",
        "        out = self.fc(output_seq[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "eeXMwYlTiNER"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_size = 3\n",
        "model = Model(input_size, hidden_size, output_size, rnn_type='GRU')\n",
        "output = model(input_tensor)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz7KiW36iPx7",
        "outputId": "28187683-5b38-43ec-e47c-de36731a0090"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3])\n"
          ]
        }
      ]
    }
  ]
}