{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP3xfoV3ksNO1YGoFFWqbFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoshiki0418/Deep_Learning/blob/main/DL_Lecture3/topic_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## トピック分類"
      ],
      "metadata": {
        "id": "Vhool0i9K2n4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データ準備"
      ],
      "metadata": {
        "id": "Mf7tMas1K6B2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMtEGFO-JqJj",
        "outputId": "037f3587-0fed-484c-f3b0-0547b4cf1a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch=='2.1.0'\n",
        "!pip install torchtext==0.16.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcRBjFEDLrO2",
        "outputId": "85565fe9-97b2-478b-f85a-3378a4ed8030"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.18.1 torch-2.1.0 triton-2.1.0\n",
            "Collecting torchtext==0.16.0\n",
            "  Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (1.26.4)\n",
            "Collecting torchdata==0.7.0 (from torchtext==0.16.0)\n",
            "  Downloading torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0) (12.6.85)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
            "Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
            "Successfully installed torchdata-0.7.0 torchtext-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "MehtKA_UK_V-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.AG_NEWS(split=\"train\")\n",
        "data = list(data)\n",
        "train_data, remaining = train_test_split(data, train_size=0.1, random_state=0)\n",
        "_, val_data = train_test_split(data,train_size=0.1, random_state=0)"
      ],
      "metadata": {
        "id": "Duaz69btLZ1W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: \"World\", 2:\"Sports\", 3:\"Business\", 4:\"Sci/Tech\"\n",
        "list(data)[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttr5yJk5MgUD",
        "outputId": "f12ad943-8b60-46d4-b778-b8bf59a6d216"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3,\n",
              "  \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"),\n",
              " (3,\n",
              "  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.'),\n",
              " (3,\n",
              "  \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "oLSMRE37Mj3d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [label for label, text in data]\n",
        "labels = pd.Series(labels)\n",
        "labels.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "beIrmZf1Mkig",
        "outputId": "0cb1a577-4f82-4d6e-d98a-63b0962eb2bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    30000\n",
              "4    30000\n",
              "2    30000\n",
              "1    30000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "text_lens = pd.Series([len(text.split()) for _, text in data])\n",
        "sns.histplot(text_lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "5ULVE_M6OLdb",
        "outputId": "bd0c4217-e526-4886-9ed8-527b913252ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGdCAYAAADzOWwgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL8tJREFUeJzt3Xt8FfWd//H3AXLjchIBk5ByC6JAlIughrNtXS4pgaZWS3YXLSpV0MIGKrBFll0ExO3iA1fwFqFdkbg/pQiPh5cCFgyJgJRwMZDKRfMQNxo0JGmlOQNIEiDf3x9uxhySAInJmSTzej4e8yBn5juTzwyT8OY735nxGGOMAAAAXKyd0wUAAAA4jUAEAABcj0AEAABcj0AEAABcj0AEAABcj0AEAABcj0AEAABcj0AEAABcr4PTBbQGVVVVKioqUpcuXeTxeJwuBwAAXAVjjE6fPq24uDi1a3f5PiAC0VUoKipSr169nC4DAAA0wokTJ9SzZ8/LtiEQXYUuXbpI+uaAer1eh6sBAABXw7Is9erVy/53/HIIRFeh+jKZ1+slEAEA0MpczXAXBlUDAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxChTTDGyO/3yxjjdCkAgFaIQIRWrToI+f1+TVqxSZZlOV0SAKAVIhChxaoZdmr2/NTsDbIsyw5CIRGdHKwWANCaEYjQYlmWpXtXZeveVdkBPT81Q5AkghAA4Dvr4HQBwOWERHSuZz4hCADQdOghAgAArkcgQqvAXWQAgOZEIEKrcOm4IQAAmhKBCK0G44YAAM2FQAQAAFyPQAQAAFyPQAQAAFyPQAQAAFyPBzOiTam+PV+SvF6vPB6PwxUBAFoDAhHaFMuylLYuV5L06owxioyMdLgiAEBrQCBCm1Pf6z4AAKgPY4gAAIDrEYgAAIDrcckMLY4xRpZl8d4yAEDQ0EOEFof3lgEAgo1AhBaJ95YBAIKJQAQAAFyPQAQAAFyPQAQAAFyPQIQ2rfpVHtyxBgC4HAIR2jTuWAMAXA0CEdo87lgDAFwJgQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALgegQgAALieo4FoyZIl8ng8AdPAgQPt5eXl5UpLS1O3bt3UuXNnpaamqqSkJGAbhYWFSklJUceOHRUdHa158+bpwoULAW127Nih4cOHKywsTP3791dGRkYwdg8AALQSjvcQ3XjjjTp58qQ97d692142Z84cbdq0SRs3btTOnTtVVFSkiRMn2ssvXryolJQUVVZWas+ePXrllVeUkZGhRYsW2W0KCgqUkpKi0aNHKy8vT7Nnz9a0adO0bdu2oO4nnGWMkd/vl9/vlzHG6XIAAC1MB8cL6NBBsbGxteb7/X6tWbNG69at05gxYyRJa9eu1aBBg7R3716NHDlS7777ro4dO6bt27crJiZGw4YN0xNPPKH58+dryZIlCg0N1erVqxUfH6+nn35akjRo0CDt3r1bK1euVHJyclD3Fc6xLEtp63IlSa/OGKPIyEiHKwIAtCSO9xB98skniouLU79+/TR58mQVFhZKknJzc3X+/HklJSXZbQcOHKjevXsrJydHkpSTk6PBgwcrJibGbpOcnCzLsnT06FG7Tc1tVLep3kZdKioqZFlWwITmV92L01w9OCERnRUS0blZtg0AaN0cDUSJiYnKyMjQ1q1btWrVKhUUFOiHP/yhTp8+reLiYoWGhioqKipgnZiYGBUXF0uSiouLA8JQ9fLqZZdrY1mWzp07V2ddy5YtU2RkpD316tWrKXYXV2BZliat2EQABQAEnaOXzCZMmGB/PWTIECUmJqpPnz7asGGDIiIiHKtrwYIFmjt3rv3ZsixCUZCERHRyugQAgAs5fsmspqioKN1www06fvy4YmNjVVlZqbKysoA2JSUl9pij2NjYWnedVX++Uhuv11tv6AoLC5PX6w2YAABA29WiAtGZM2f06aefqkePHhoxYoRCQkKUlZVlL8/Pz1dhYaF8Pp8kyefz6fDhwyotLbXbZGZmyuv1KiEhwW5TcxvVbaq3AQAA4Ggg+vWvf62dO3fqs88+0549e/Szn/1M7du31z333KPIyEhNnTpVc+fO1Xvvvafc3Fw98MAD8vl8GjlypCRp3LhxSkhI0H333ac///nP2rZtmxYuXKi0tDSFhYVJkqZPn67//d//1aOPPqqPP/5YL774ojZs2KA5c+Y4uesAAKAFcXQM0RdffKF77rlHX331la699lr94Ac/0N69e3XttddKklauXKl27dopNTVVFRUVSk5O1osvvmiv3759e23evFkzZsyQz+dTp06dNGXKFC1dutRuEx8fry1btmjOnDl69tln1bNnT7300kvccg8AAGyOBqL169dfdnl4eLjS09OVnp5eb5s+ffronXfeuex2Ro0apUOHDjWqRgAA0Pa1qDFEAAAATiAQAQAA1yMQAQAA1yMQAQAA1yMQwTHN/e4yAACuFoEIjuHdZQCAloJABEfx7jIAQEtAIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIILrcLs/AOBSBCK4Drf7AwAuRSCCK3G7PwCgJgIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwPQIRAABwvQ5OFwD3McbIsiwZY5wuBQAASfQQwQGWZWnSik2yLMvpUgAAkEQggkNCIjo5XQIAADYCEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEQAAcD0CEVzLGCO/3y9jjNOlAAAcRiCCa1mWpUkrNsmyLKdLAQA4jEAEVwuJ6OR0CQCAFoBABAAAXI9ABAAAXK/FBKInn3xSHo9Hs2fPtueVl5crLS1N3bp1U+fOnZWamqqSkpKA9QoLC5WSkqKOHTsqOjpa8+bN04ULFwLa7NixQ8OHD1dYWJj69++vjIyMIOwRAABoLVpEIDpw4IB++9vfasiQIQHz58yZo02bNmnjxo3auXOnioqKNHHiRHv5xYsXlZKSosrKSu3Zs0evvPKKMjIytGjRIrtNQUGBUlJSNHr0aOXl5Wn27NmaNm2atm3bFrT9AwAALZvjgejMmTOaPHmy/vu//1vXXHONPd/v92vNmjVasWKFxowZoxEjRmjt2rXas2eP9u7dK0l69913dezYMb366qsaNmyYJkyYoCeeeELp6emqrKyUJK1evVrx8fF6+umnNWjQIM2cOVP/8A//oJUrVzqyvwAAoOVxPBClpaUpJSVFSUlJAfNzc3N1/vz5gPkDBw5U7969lZOTI0nKycnR4MGDFRMTY7dJTk6WZVk6evSo3ebSbScnJ9vbqEtFRYUsywqYAABA29XByW++fv16HTx4UAcOHKi1rLi4WKGhoYqKigqYHxMTo+LiYrtNzTBUvbx62eXaWJalc+fOKSIiotb3XrZsmR5//PFG7xcAAGhdHOshOnHihB555BG99tprCg8Pd6qMOi1YsEB+v9+eTpw44XRJAACgGTkWiHJzc1VaWqrhw4erQ4cO6tChg3bu3KnnnntOHTp0UExMjCorK1VWVhawXklJiWJjYyVJsbGxte46q/58pTZer7fO3iFJCgsLk9frDZgAAEDb5VggGjt2rA4fPqy8vDx7uuWWWzR58mT765CQEGVlZdnr5Ofnq7CwUD6fT5Lk8/l0+PBhlZaW2m0yMzPl9XqVkJBgt6m5jeo21dsAAABwbAxRly5ddNNNNwXM69Spk7p162bPnzp1qubOnauuXbvK6/Vq1qxZ8vl8GjlypCRp3LhxSkhI0H333afly5eruLhYCxcuVFpamsLCwiRJ06dP1wsvvKBHH31UDz74oLKzs7VhwwZt2bIluDsMAABaLEcHVV/JypUr1a5dO6WmpqqiokLJycl68cUX7eXt27fX5s2bNWPGDPl8PnXq1ElTpkzR0qVL7Tbx8fHasmWL5syZo2effVY9e/bUSy+9pOTkZCd2CQAAtEAtKhDt2LEj4HN4eLjS09OVnp5e7zp9+vTRO++8c9ntjho1SocOHWqKEgEAQBvk+HOIAAAAnEYgQlAYY+T3+2WMcboUAABqIRAhKCzL0qQVm3jqNwCgRSIQIWhCIjo5XQIAAHUiEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAHiSdoA4HYEIkA8SRsA3I5ABPwfnqQNAO5FIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK7XwekC0LYZY2RZlowxTpcCAEC96CFCs7IsS5NWbJJlWU6XAgBAvQhEaHYhEZ2cLgEAgMsiEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANcjEAEAANdrVCDq16+fvvrqq1rzy8rK1K9fv+9cFAAAQDA1KhB99tlnunjxYq35FRUV+vLLL79zUQAAAMHUoJe7/uEPf7C/3rZtmyIjI+3PFy9eVFZWlvr27dtkxQEAAARDgwLRXXfdJUnyeDyaMmVKwLKQkBD17dtXTz/9dJMVBwAAEAwNCkRVVVWSpPj4eB04cEDdu3dvlqIAAACCqUGBqFpBQUFT1wEAAOCYRgUiScrKylJWVpZKS0vtnqNqL7/88ncuDAAAIFgaFYgef/xxLV26VLfccot69Oghj8fT1HUBAAAETaMC0erVq5WRkaH77ruvqesBAAAIukY9h6iyslJ/93d/19S1AAAAOKJRgWjatGlat25dU9cCAADgiEZdMisvL9fvfvc7bd++XUOGDFFISEjA8hUrVjRJcYATjDGyLEter5fxcQDgEo0KRB9++KGGDRsmSTpy5EjAMv4BQWtnWZYmrdik1+feEfA0dgBA29WoS2bvvfdevVN2dvZVb2fVqlUaMmSIvF6vvF6vfD6f/vjHP9rLy8vLlZaWpm7duqlz585KTU1VSUlJwDYKCwuVkpKijh07Kjo6WvPmzdOFCxcC2uzYsUPDhw9XWFiY+vfvr4yMjMbsNlwkJKKT0yUAAIKoUYGoqfTs2VNPPvmkcnNz9cEHH2jMmDG68847dfToUUnSnDlztGnTJm3cuFE7d+5UUVGRJk6caK9/8eJFpaSkqLKyUnv27NErr7yijIwMLVq0yG5TUFCglJQUjR49Wnl5eZo9e7amTZumbdu2BX1/AQBAy9SoS2ajR4++7KWxq+0luuOOOwI+/+Y3v9GqVau0d+9e9ezZU2vWrNG6des0ZswYSdLatWs1aNAg7d27VyNHjtS7776rY8eOafv27YqJidGwYcP0xBNPaP78+VqyZIlCQ0O1evVqxcfH2+9YGzRokHbv3q2VK1cqOTm5MbuPy2D8DQCgNWpUD9GwYcM0dOhQe0pISFBlZaUOHjyowYMHN6qQixcvav369Tp79qx8Pp9yc3N1/vx5JSUl2W0GDhyo3r17KycnR5KUk5OjwYMHKyYmxm6TnJwsy7LsXqacnJyAbVS3qd5GXSoqKmRZVsCEq1M9/oZjBgBoTRrVQ7Ry5co65y9ZskRnzpxp0LYOHz4sn8+n8vJyde7cWW+++aYSEhKUl5en0NBQRUVFBbSPiYlRcXGxJKm4uDggDFUvr152uTaWZencuXOKiIioVdOyZcv0+OOPN2g/8C3G3wAAWpsmHUN07733Nvg9ZgMGDFBeXp727dunGTNmaMqUKTp27FhTltVgCxYskN/vt6cTJ044Wg8AAGhejX65a11ycnIUHh7eoHVCQ0PVv39/SdKIESN04MABPfvss5o0aZIqKytVVlYW0EtUUlKi2NhYSVJsbKz2798fsL3qu9Bqtrn0zrSSkhJ5vd46e4ckKSwsTGFhYQ3aDwAA0Ho1KhDVvNNL+mYg7cmTJ/XBBx/oscce+04FVVVVqaKiQiNGjFBISIiysrKUmpoqScrPz1dhYaF8Pp8kyefz6Te/+Y1KS0sVHR0tScrMzJTX61VCQoLd5p133gn4HpmZmfY2AAAAGhWILn1YXbt27TRgwAAtXbpU48aNu+rtLFiwQBMmTFDv3r11+vRprVu3Tjt27NC2bdsUGRmpqVOnau7cueratau8Xq9mzZoln8+nkSNHSpLGjRunhIQE3XfffVq+fLmKi4u1cOFCpaWl2T0806dP1wsvvKBHH31UDz74oLKzs7VhwwZt2bKlMbsOAADaoEYForVr1zbJNy8tLdX999+vkydPKjIyUkOGDNG2bdv0ox/9SNI3g7fbtWun1NRUVVRUKDk5WS+++KK9fvv27bV582bNmDFDPp9PnTp10pQpU7R06VK7TXx8vLZs2aI5c+bo2WefVc+ePfXSSy9xyz0AALB9pzFEubm5+uijjyRJN954o26++eYGrb9mzZrLLg8PD1d6errS09PrbdOnT59al8QuNWrUKB06dKhBtQEAAPdoVCAqLS3V3XffrR07dtgDnsvKyjR69GitX79e1157bVPWCAAA0Kwaddv9rFmzdPr0aR09elSnTp3SqVOndOTIEVmWpV/96ldNXSMAAECzalQP0datW7V9+3YNGjTInpeQkKD09PQGDaoGAABoCRrVQ1RVVaWQkJBa80NCQlRVVfWdiwIAAAimRgWiMWPG6JFHHlFRUZE978svv9ScOXM0duzYJisOAAAgGBoViF544QVZlqW+ffvquuuu03XXXaf4+HhZlqXnn3++qWsEAABoVo0aQ9SrVy8dPHhQ27dv18cffyxJGjRoUK23ygMAALQGDeohys7OVkJCgizLksfj0Y9+9CPNmjVLs2bN0q233qobb7xR77//fnPVCgAA0CwaFIieeeYZPfTQQ/J6vbWWRUZG6pe//KVWrFjRZMUBAAAEQ4MC0Z///GeNHz++3uXjxo1Tbm7udy4KAAAgmBoUiEpKSuq83b5ahw4d9Je//OU7FwUAABBMDQpE3/ve93TkyJF6l3/44Yfq0aPHdy4KAAAgmBoUiH784x/rscceU3l5ea1l586d0+LFi/WTn/ykyYoDAAAIhgbddr9w4UK98cYbuuGGGzRz5kwNGDBAkvTxxx8rPT1dFy9e1L//+783S6EAAADNpUGBKCYmRnv27NGMGTO0YMECGWMkSR6PR8nJyUpPT1dMTEyzFAoEmzFGfr9fkuT1euXxeByuCADQXBr8YMY+ffronXfe0d/+9jcdP35cxhhdf/31uuaaa5qjPsAxlmUpbd03d02+OmOMIiMjHa4IANBcGvWkakm65pprdOuttzZlLUCLExLR2ekSAABB0Kh3mQEAALQlBCIAAOB6BCIAAOB6BCIAAOB6BCIAAOB6BCIAAOB6BCIAAOB6BCIAAOB6jX4wI1CTMUaWZdmvcwEAoDWhhwhNwrIsTVqxSZZlOV0KAAANRiBCkwmJ6OR0CQAANAqBCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCAAAuB6BCLgKxhj5/X4ZY5wuBQDQDAhEwFWwLEuTVmySZVlOlwIAaAYEIuAqhUR0croEAEAzIRABAADXIxABAADXIxABAADXIxABAADXIxABAADXIxABAADXczQQLVu2TLfeequ6dOmi6Oho3XXXXcrPzw9oU15errS0NHXr1k2dO3dWamqqSkpKAtoUFhYqJSVFHTt2VHR0tObNm6cLFy4EtNmxY4eGDx+usLAw9e/fXxkZGc29e67AAwsBAG2Bo4Fo586dSktL0969e5WZmanz589r3LhxOnv2rN1mzpw52rRpkzZu3KidO3eqqKhIEydOtJdfvHhRKSkpqqys1J49e/TKK68oIyNDixYtstsUFBQoJSVFo0ePVl5enmbPnq1p06Zp27ZtQd3ftogHFgIA2oIOTn7zrVu3BnzOyMhQdHS0cnNzdfvtt8vv92vNmjVat26dxowZI0lau3atBg0apL1792rkyJF69913dezYMW3fvl0xMTEaNmyYnnjiCc2fP19LlixRaGioVq9erfj4eD399NOSpEGDBmn37t1auXKlkpOTg77fbQ0PLAQAtHYtagyR3++XJHXt2lWSlJubq/PnzyspKcluM3DgQPXu3Vs5OTmSpJycHA0ePFgxMTF2m+TkZFmWpaNHj9ptam6juk31Ni5VUVEhy7ICJgAA0Ha1mEBUVVWl2bNn6/vf/75uuukmSVJxcbFCQ0MVFRUV0DYmJkbFxcV2m5phqHp59bLLtbEsS+fOnatVy7JlyxQZGWlPvXr1apJ9BAAALVOLCURpaWk6cuSI1q9f73QpWrBggfx+vz2dOHHC6ZIAAEAzcnQMUbWZM2dq8+bN2rVrl3r27GnPj42NVWVlpcrKygJ6iUpKShQbG2u32b9/f8D2qu9Cq9nm0jvTSkpK5PV6FRERUauesLAwhYWFNcm+AQCAls/RHiJjjGbOnKk333xT2dnZio+PD1g+YsQIhYSEKCsry56Xn5+vwsJC+Xw+SZLP59Phw4dVWlpqt8nMzJTX61VCQoLdpuY2qttUbwMAALiboz1EaWlpWrdund5++2116dLFHvMTGRmpiIgIRUZGaurUqZo7d666du0qr9erWbNmyefzaeTIkZKkcePGKSEhQffdd5+WL1+u4uJiLVy4UGlpaXYvz/Tp0/XCCy/o0Ucf1YMPPqjs7Gxt2LBBW7ZscWzfAQBAy+FoD9GqVavk9/s1atQo9ejRw55ef/11u83KlSv1k5/8RKmpqbr99tsVGxurN954w17evn17bd68We3bt5fP59O9996r+++/X0uXLrXbxMfHa8uWLcrMzNTQoUP19NNP66WXXuKWewAAIMnhHqKrebpxeHi40tPTlZ6eXm+bPn366J133rnsdkaNGqVDhw41uEYAAND2tZi7zAAAAJxCIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIAAK5HIAIawBgjv99/VY+MAAC0HgQioAEsy9KkFZtkWZbTpQAAmhCBCA3m9l6SkIhOTpcAAGhiBCI0GL0kAIC2hkCERqGXBADQlhCIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIcFWMMfL7/TLGOF1Ki8JxAYC2gUCEq2JZliat2CTLspwupUXhuABA20AgwlULiejkdAktEscFAFo/AhEAAHA9AhEAAHA9AhEAAHA9AhHqxR1UAAC3IBChXtxBBQBwCwIRLos7qAAAbkAgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgAgAArkcgQi281LXhOGYA0LoRiFALL3VtOI4ZALRuBCLUiZe6NhzHDABaLwIRAABwPQIRAABwPQIRAABwPUcD0a5du3THHXcoLi5OHo9Hb731VsByY4wWLVqkHj16KCIiQklJSfrkk08C2pw6dUqTJ0+W1+tVVFSUpk6dqjNnzgS0+fDDD/XDH/5Q4eHh6tWrl5YvX97cuwYAAFoRRwPR2bNnNXToUKWnp9e5fPny5Xruuee0evVq7du3T506dVJycrLKy8vtNpMnT9bRo0eVmZmpzZs3a9euXXr44Yft5ZZlady4cerTp49yc3P11FNPacmSJfrd737X7PsHAABahw5OfvMJEyZowoQJdS4zxuiZZ57RwoULdeedd0qS/ud//kcxMTF66623dPfdd+ujjz7S1q1bdeDAAd1yyy2SpOeff14//vGP9V//9V+Ki4vTa6+9psrKSr388ssKDQ3VjTfeqLy8PK1YsSIgOAEAAPdqsWOICgoKVFxcrKSkJHteZGSkEhMTlZOTI0nKyclRVFSUHYYkKSkpSe3atdO+ffvsNrfffrtCQ0PtNsnJycrPz9ff/va3Or93RUWFLMsKmAAAQNvVYgNRcXGxJCkmJiZgfkxMjL2suLhY0dHRAcs7dOigrl27BrSpaxs1v8elli1bpsjISHvq1avXd98hAADQYrXYQOSkBQsWyO/329OJEyecLqnZVb96gtdPAADcyNExRJcTGxsrSSopKVGPHj3s+SUlJRo2bJjdprS0NGC9Cxcu6NSpU/b6sbGxKikpCWhT/bm6zaXCwsIUFhbWJPvRWliWpXtXZUuS0n8+wuFqAAAIrhbbQxQfH6/Y2FhlZWXZ8yzL0r59++Tz+SRJPp9PZWVlys3NtdtkZ2erqqpKiYmJdptdu3bp/PnzdpvMzEwNGDBA11xzTZD2pnUIieiskIjOTpcBAEDQORqIzpw5o7y8POXl5Un6ZiB1Xl6eCgsL5fF4NHv2bP3Hf/yH/vCHP+jw4cO6//77FRcXp7vuukuSNGjQII0fP14PPfSQ9u/frz/96U+aOXOm7r77bsXFxUmSfv7znys0NFRTp07V0aNH9frrr+vZZ5/V3LlzHdprAADQ0jh6yeyDDz7Q6NGj7c/VIWXKlCnKyMjQo48+qrNnz+rhhx9WWVmZfvCDH2jr1q0KDw+313nttdc0c+ZMjR07Vu3atVNqaqqee+45e3lkZKTeffddpaWlacSIEerevbsWLVrELfcAAMDmaCAaNWrUZQfwejweLV26VEuXLq23TdeuXbVu3brLfp8hQ4bo/fffb3SdAACgbWuxY4gAAACChUAENLHqRxjw+AIAaD0IREATsyxLk1Zs4gnnANCKEIiAZhAS0cnpEgAADUAgAgAArkcgAgAArkcgAgAArkcgAgAArkcgcjFuDwcA4BsEIhfj9nAAAL5BIHI5bg9vPvTAAUDrQSACmgk9cADQehCIgGZEDxwAtA4EIgAA4HoEIgAA4HodnC4AwWeMkWVZDPYFAOD/0EPkQgz2BQAgEIHIpRjsCwDAt7hkBgRB9WVKSfJ6vfJ4PA5XBACoiR4iIAgsy9K9q7J176psLlUCQAtEDxEQJCERnZ0uAQBQD3qIAACA6xGIAACA6xGIAACA6xGIXII3rwMAUD8CkUvwMEYAAOpHIHIRHsYIAEDdCERAkHH5EgBaHgIREGRcvgSAlodABDiAy5cA0LLwpOo2rvodWlyeAQCgfvQQtXFcngEA4MoIRC7A5ZmWqebgagZaA4CzCESAQ2r23tGTBwDOIhABDqrZe1f9Nb1FABB8BCKghaG3CACCj0AEtECM+wKA4CIQAQAA1yMQtTGMP2lb+PsEgOAgELUxjD9pW5ry75NwBQD1IxC1QYw/aVsa+/d5aQAiLANA/QhEQCvQmN6dugJQSEQneooAoA4EIqAVuFLvTn1Pva6rd4meIgCojUAEtBI1e3cuDT9+v79BT73msioABCIQAa2IZVm6d1W27l2VXSv81PXU68u5NFwBgJt1cLoANA1jjCzL4h82FwiJ6HzJ58b19liWpbR1uZKkV2eMUWRk5HeuDQBaK3qI2gjGhaAxQiI61wpYAOBGBKI2hHEhAAA0DpfMWrHqy2TVXwONVT2eyOv1yuPxOF0OAAQdPUSt2KUDbIHGqnnJlcHWANyIHqJWjvEfaCrVl1yrg7Yk/b/po+XxeNSlSxedPn3a/lNSvb1J1T2X9DYBaE1c1UOUnp6uvn37Kjw8XImJidq/f7/TJV2V+p49w//e0VyqB1tX9xx98cUX9p81eyWrz8Wqqir7HK1+JhK9TABaE9cEotdff11z587V4sWLdfDgQQ0dOlTJyckqLS11urQrutyzZ4DmVt1z9O2f396ZVjMw1TxHQyI61XkZrmagrxmiqr+u/rM6RF3alnAFoLm4JhCtWLFCDz30kB544AElJCRo9erV6tixo15++WWnS6tX4CsYAm+P5o4ytBR1BaVLl9UMR3WFqJo9UDXD/qU9VHX1StUXnmour+/VJvWt09Thi15doOVzxRiiyspK5ebmasGCBfa8du3aKSkpSTk5ObXaV1RUqKKiwv7s9/slqdl6ZKq3fynLspT239v15N2J+vpv3/RkffHFF5Kkc2V/VVFRkT2/qKiLPe9c2V/1xRdf2P/4XDq/5vo1511uW9Xr1Pd1ddvGfv+62ta1f1fz/RtzrOrbZks8vvXtX1Me3/pq/S7H90LFuYCvi4qKdL786/9bp8ieV92uuuZL50uyfy7+df0+pT+UJK/XG/Dz8q/r9wUsr16nvq9rrrPwrcOSpGfv+zt5vV41heraqmsFUFtzPBy2QXdiGxf48ssvjSSzZ8+egPnz5s0zt912W632ixcvNpKYmJiYmJiY2sB04sSJK2YFV/QQNdSCBQs0d+5c+3NVVZVOnTqlkJAQ9e7dWydOnHD1//Isy1KvXr1cfxwkjkVNHItvcBy+xbH4FsfiW8E8FsYYnT59WnFxcVds64pA1L17d7Vv314lJSUB80tKShQbG1urfVhYmMLCwgLmRUVF2V1vXq/X9Se0xHGoiWPxLY7FNzgO3+JYfItj8a1gHYurvRTnikHVoaGhGjFihLKysux5VVVVysrKks/nc7AyAADQEriih0iS5s6dqylTpuiWW27RbbfdpmeeeUZnz57VAw884HRpAADAYa4JRJMmTdJf/vIXLVq0SMXFxRo2bJi2bt2qmJiYq95GWFiYFi9eXOtymttwHL7FsfgWx+IbHIdvcSy+xbH4Vks9Fh5jeDAGAABwN1eMIQIAALgcAhEAAHA9AhEAAHA9AhEAAHA9AtFVSk9PV9++fRUeHq7ExETt37/f6ZKa3bJly3TrrbeqS5cuio6O1l133aX8/PyANqNGjZLH4wmYpk+f7lDFzWPJkiW19nHgwIH28vLycqWlpalbt27q3LmzUlNTaz0EtK3o27dvrWPh8XiUlpYmqW2fD7t27dIdd9yhuLg4eTwevfXWWwHLjTFatGiRevTooYiICCUlJemTTz4JaHPq1ClNnjxZXq9XUVFRmjp1qs6cORPEvfjuLncczp8/r/nz52vw4MHq1KmT4uLidP/996uoqChgG3WdR08++WSQ9+S7u9I58Ytf/KLWfo4fPz6gTVs4J6QrH4u6fm94PB499dRTdhunzwsC0VV4/fXXNXfuXC1evFgHDx7U0KFDlZycrNLSUqdLa1Y7d+5UWlqa9u7dq8zMTJ0/f17jxo3T2bNnA9o99NBDOnnypD0tX77coYqbz4033hiwj7t377aXzZkzR5s2bdLGjRu1c+dOFRUVaeLEiQ5W23wOHDgQcBwyMzMlSf/4j/9ot2mr58PZs2c1dOhQpaen17l8+fLleu6557R69Wrt27dPnTp1UnJyssrLy+02kydP1tGjR5WZmanNmzdr165devjhh4O1C03icsfh66+/1sGDB/XYY4/p4MGDeuONN5Sfn6+f/vSntdouXbo04DyZNWtWMMpvUlc6JyRp/PjxAfv5+9//PmB5WzgnpCsfi5rH4OTJk3r55Zfl8XiUmpoa0M7R86JJ3p7axt12220mLS3N/nzx4kUTFxdnli1b5mBVwVdaWmokmZ07d9rz/v7v/9488sgjzhUVBIsXLzZDhw6tc1lZWZkJCQkxGzdutOd99NFHRpLJyckJUoXOeeSRR8x1111nqqqqjDHuOB+MMUaSefPNN+3PVVVVJjY21jz11FP2vLKyMhMWFmZ+//vfG2OMOXbsmJFkDhw4YLf54x//aDwej/nyyy+DVntTuvQ41GX//v1Gkvn888/teX369DErV65s3uKCrK5jMWXKFHPnnXfWu05bPCeMubrz4s477zRjxowJmOf0eUEP0RVUVlYqNzdXSUlJ9rx27dopKSlJOTk5DlYWfH6/X5LUtWvXgPmvvfaaunfvrptuukkLFizQ119/7UR5zeqTTz5RXFyc+vXrp8mTJ6uwsFCSlJubq/PnzwecHwMHDlTv3r3b/PlRWVmpV199VQ8++KA8Ho893w3nw6UKCgpUXFwccB5ERkYqMTHRPg9ycnIUFRWlW265xW6TlJSkdu3aad++fUGvOVj8fr88Ho+ioqIC5j/55JPq1q2bbr75Zj311FO6cOGCMwU2sx07dig6OloDBgzQjBkz9NVXX9nL3HpOlJSUaMuWLZo6dWqtZU6eF655UnVj/fWvf9XFixdrPdE6JiZGH3/8sUNVBV9VVZVmz56t73//+7rpppvs+T//+c/Vp08fxcXF6cMPP9T8+fOVn5+vN954w8Fqm1ZiYqIyMjI0YMAAnTx5Uo8//rh++MMf6siRIyouLlZoaGitX/YxMTEqLi52puAgeeutt1RWVqZf/OIX9jw3nA91qf67ruv3RPWy4uJiRUdHByzv0KGDunbt2mbPlfLycs2fP1/33HNPwEs8f/WrX2n48OHq2rWr9uzZowULFujkyZNasWKFg9U2vfHjx2vixImKj4/Xp59+qn/7t3/ThAkTlJOTo/bt27vynJCkV155RV26dKk1tMDp84JAhKuSlpamI0eOBIydkRRwrXvw4MHq0aOHxo4dq08//VTXXXddsMtsFhMmTLC/HjJkiBITE9WnTx9t2LBBERERDlbmrDVr1mjChAmKi4uz57nhfMDVOX/+vP7pn/5JxhitWrUqYNncuXPtr4cMGaLQ0FD98pe/1LJly1rc6xy+i7vvvtv+evDgwRoyZIiuu+467dixQ2PHjnWwMme9/PLLmjx5ssLDwwPmO31ecMnsCrp376727dvXumuopKREsbGxDlUVXDNnztTmzZv13nvvqWfPnpdtm5iYKEk6fvx4MEpzRFRUlG644QYdP35csbGxqqysVFlZWUCbtn5+fP7559q+fbumTZt22XZuOB8k2X/Xl/s9ERsbW+tGjAsXLujUqVNt7lypDkOff/65MjMzA3qH6pKYmKgLFy7os88+C06BDunXr5+6d+9u/zy46Zyo9v777ys/P/+Kvzuk4J8XBKIrCA0N1YgRI5SVlWXPq6qqUlZWlnw+n4OVNT9jjGbOnKk333xT2dnZio+Pv+I6eXl5kqQePXo0c3XOOXPmjD799FP16NFDI0aMUEhISMD5kZ+fr8LCwjZ9fqxdu1bR0dFKSUm5bDs3nA+SFB8fr9jY2IDzwLIs7du3zz4PfD6fysrKlJuba7fJzs5WVVWVHRzbguow9Mknn2j79u3q1q3bFdfJy8tTu3btal0+amu++OILffXVV/bPg1vOiZrWrFmjESNGaOjQoVdsG/TzwrHh3K3I+vXrTVhYmMnIyDDHjh0zDz/8sImKijLFxcVOl9asZsyYYSIjI82OHTvMyZMn7enrr782xhhz/Phxs3TpUvPBBx+YgoIC8/bbb5t+/fqZ22+/3eHKm9a//Mu/mB07dpiCggLzpz/9ySQlJZnu3bub0tJSY4wx06dPN7179zbZ2dnmgw8+MD6fz/h8Poerbj4XL140vXv3NvPnzw+Y39bPh9OnT5tDhw6ZQ4cOGUlmxYoV5tChQ/bdU08++aSJiooyb7/9tvnwww/NnXfeaeLj4825c+fsbYwfP97cfPPNZt++fWb37t3m+uuvN/fcc49Tu9QolzsOlZWV5qc//anp2bOnycvLC/i9UVFRYYwxZs+ePWblypUmLy/PfPrpp+bVV1811157rbn//vsd3rOGu9yxOH36tPn1r39tcnJyTEFBgdm+fbsZPny4uf766015ebm9jbZwThhz5Z8PY4zx+/2mY8eOZtWqVbXWbwnnBYHoKj3//POmd+/eJjQ01Nx2221m7969TpfU7CTVOa1du9YYY0xhYaG5/fbbTdeuXU1YWJjp37+/mTdvnvH7/c4W3sQmTZpkevToYUJDQ833vvc9M2nSJHP8+HF7+blz58w///M/m2uuucZ07NjR/OxnPzMnT550sOLmtW3bNiPJ5OfnB8xv6+fDe++9V+fPw5QpU4wx39x6/9hjj5mYmBgTFhZmxo4dW+sYffXVV+aee+4xnTt3Nl6v1zzwwAPm9OnTDuxN413uOBQUFNT7e+O9994zxhiTm5trEhMTTWRkpAkPDzeDBg0y//mf/xkQElqLyx2Lr7/+2owbN85ce+21JiQkxPTp08c89NBDtf4j3RbOCWOu/PNhjDG//e1vTUREhCkrK6u1fks4LzzGGNOsXVAAAAAtHGOIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6xGIAACA6/1/0Bhz9sZWya8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### トークン化"
      ],
      "metadata": {
        "id": "Ch8USMP2bv93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 単語(token)に分割する(tokenize)\n",
        "*  torchtext.data.utils.get_tokenizerを使用する"
      ],
      "metadata": {
        "id": "9l5rvxQWb8Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer"
      ],
      "metadata": {
        "id": "ex_eWDhTbvSr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "print(tokenizer(\"I am a student\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64S0z4rKcVHT",
        "outputId": "5c7589cf-6194-46b7-af91-abdae35ca304"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'am', 'a', 'student']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### イテレータ作成"
      ],
      "metadata": {
        "id": "TEurAxjNdSD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 各単語(token)を返すイテレータを作る"
      ],
      "metadata": {
        "id": "RZbfdRPQf5I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "VacUWrZ7dV-f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(yield_tokens(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TV_1g54eTqB",
        "outputId": "c022eb1f-5c6b-461f-e1ed-7e4b3d9b0e04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wall',\n",
              " 'st',\n",
              " '.',\n",
              " 'bears',\n",
              " 'claw',\n",
              " 'back',\n",
              " 'into',\n",
              " 'the',\n",
              " 'black',\n",
              " '(',\n",
              " 'reuters',\n",
              " ')',\n",
              " 'reuters',\n",
              " '-',\n",
              " 'short-sellers',\n",
              " ',',\n",
              " 'wall',\n",
              " 'street',\n",
              " \"'\",\n",
              " 's',\n",
              " 'dwindling\\\\band',\n",
              " 'of',\n",
              " 'ultra-cynics',\n",
              " ',',\n",
              " 'are',\n",
              " 'seeing',\n",
              " 'green',\n",
              " 'again',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 辞書作成"
      ],
      "metadata": {
        "id": "R0tqXYv5f2K2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* torchtext.vacab.build_vocab_from_iteratorを使用する\n",
        "  * iterator: 単語(token)を返すイテレータ\n",
        "  * min_freq: 辞書に登録する単語の最小頻度 (デフォルトは1)\n",
        "  * specials: <unk>などの特別なtokenを予約する\n",
        "  * vocab[‘word’]のようにしてその単語のindexを取得する\n",
        "  * .get_itos() で全tokenのリストを取得する\n",
        "  * .set_default_index(index)で辞書にない単語のデフォルトのindexを指定する"
      ],
      "metadata": {
        "id": "sViXhilvgDeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "o578X5Wvf87k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(iterator=yield_tokens(data), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "Gd8NUj2ujFn4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[\"hello\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdPABnIljsof",
        "outputId": "7121bd41-b716-4825-86bc-14216106a276"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12544"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 存在しない単語のindex\n",
        "vocab[\"unitabahahahu\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1LfqTdNjxKg",
        "outputId": "dc6a06ef-ec24-4cb2-c385-dd67efd42424"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexからの逆引き\n",
        "vocab.get_itos()[12544]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HSjBKVWLj3yI",
        "outputId": "52117e45-0bbd-4916-b1f0-f31cd9d14e05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader作成"
      ],
      "metadata": {
        "id": "Sd2TGSYPkPsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi6fVoCOkN6F",
        "outputId": "faad2e69-bd61-4739-9533-4ff79f269319"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2,\n",
              "  'SECOND LOOKSnapshots from the latest in college football The boys of Pi Kappa Phi better look out. Mississippi State pulls off the SEC stunner of this Millennium, beating Ron Zook and Florida 38-31.'),\n",
              " (1,\n",
              "  'Summit of French-Speaking Countries Condemns Ivory Coast Leaders at a summit in Burkina Faso of mostly French-speaking nations have condemned authorities in divided Ivory Coast for resuming hostilities in the rebel-held north earlier this month.'),\n",
              " (4,\n",
              "  'Lost faith in Internet Explorer? Try another browser Microsoft has won the browser wars, but a battle is raging for the runner-up spot and one of the contenders has recently been refreshed.')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "2Whnb7EqIeIC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch: [(label, text), (label, text),...,]\n",
        "def collate_batch(batch):\n",
        "    label_list = []\n",
        "    text_list = []\n",
        "    for label, text in batch:\n",
        "        label_list.append(label - 1)\n",
        "        text_list.append(torch.tensor([vocab[token] for token in tokenizer(text)])) # [\"I am a student\"] - >[\"I\", \"am\", \"a\", \"student\"]\n",
        "\n",
        "    # padding\n",
        "    label_list = torch.tensor(label_list)\n",
        "    text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
        "    return label_list, text_list"
      ],
      "metadata": {
        "id": "NvkhChe6IfFN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=8, collate_fn=collate_batch, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8, collate_fn=collate_batch, shuffle=False)"
      ],
      "metadata": {
        "id": "DtYc4o3eKAi8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label, text = next(iter(train_loader))\n",
        "print(label)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF34_hkXK93S",
        "outputId": "a0e8a52e-41e0-4c77-e77e-680ce11f91a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3, 1, 3, 3, 1, 0])\n",
            "tensor([[ 1533,  1145,   492,  1839,     4,  2906,  4113,    12,     9,   132,\n",
            "           229,    12,     9,   206, 11273,     7,     2,   127,  1486,  1533,\n",
            "          1768,   492,     8,   185,     2,   381,    63,   786,     6,     2,\n",
            "            54,    12,     9,   118,   733,    21,   166,     4,   741,  2906,\n",
            "         17272,    12,   132,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 2797,  1444,  6618,   280,    20,  6538,    23,    73,    13,    27,\n",
            "            14,    15,    51,     1,     9,     1,  1834,    92,  1143,  6618,\n",
            "           280,    10,    56,    19,    30,   758,  7688,     6,  6678,  1133,\n",
            "            66,     5,   970,     4,   274,  1017,     3,  1807,    26,     1,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 1129,  3702, 12211,   637,    72,     5,   202,   489,    41,  3174,\n",
            "         32671,  3159,   122,  6336,  2251,  3686,  8071,    52,  5278,     6,\n",
            "             2,  8381,    80,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 2482,   402,  1215,    63,   188,   617,   859,   141,    50,   437,\n",
            "            61,  1201,   444,  3046,  2482,    28,   192,    32,  1215,    63,\n",
            "             5,   237,   155,   859,    17,  3568,     8,   158,  2526, 36646,\n",
            "            42,  7053,     4,   617,    10,  9868,    12,  2931,   223,   932,\n",
            "             7,   510,     1,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  383,  4147,    10, 11085, 14837,     7,  4018,    18,  1984,     2,\n",
            "           168,   278,   720,     4,   763,     5,   268,     8,   658,  1975,\n",
            "             4,  1954,  1984,    12,     9,  3737, 17348,     3,    45,   287,\n",
            "            10,  3002,    25,  1985,     4, 12045,   862,     6,  1434,  3855,\n",
            "             3,   679,   396,   125, 18151,  4629,    26,    74,     1,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 8597,  4376,  1417,    11,    77,  5790,   868,  8597,   154,     4,\n",
            "          7445,    22,  2996,     6,   506,    11,     2,    77,   868,  1694,\n",
            "             3,    18,  1417,     4,  1544,  1329,   847,     3,  1228,  3429,\n",
            "             3,     8,    99,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 1006,    16, 10800,    16,   747,  5296,  1022,    13,    31,    14,\n",
            "            31,    15,    90,  1386,  2219,    35,  4956,    19,     2,   500,\n",
            "             6,     2,  6856,  1022,   174,  2271,     3,     2,  2076,     6,\n",
            "           403,  5794,    46,    72,    61,     6,   403,    16,     9, 15446,\n",
            "         22575,     1,    67,  4956,     2,  5972,   160,     6,     2,   335,\n",
            "            75,   747, 11825,     2,   803,    66,    22, 33359, 15611,     1],\n",
            "        [  188,   565,    16,     9,  7723,  3246,    11,    32,   481,    13,\n",
            "            31,    14,    31,    15,     2, 17765,  3306,     6,     5,  3320,\n",
            "           380,   565,     7,    70,  2990,    18,    32,  3995,     4,   378,\n",
            "           283,    60,     3,   301,    34,    67,  3681,    48,   767,  1122,\n",
            "          1264,    18,   283,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### word embedding matrixの作成"
      ],
      "metadata": {
        "id": "nR0aJhTjLxBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensimのword2Vecを使用"
      ],
      "metadata": {
        "id": "T5sMm2mlL7Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive のマウント\n",
        "from google.colab import drive\n",
        "drive_path = '/content/drive'\n",
        "drive.mount(drive_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyR-vpegL7-U",
        "outputId": "a35aa256-5231-405f-f8f6-93634965256b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load_word2vec_format(f'{drive_path}/MyDrive/Deep_Learning/DL_Lecture3/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "metadata": {
        "id": "lsNvE5MjODS1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "xe3hskzlOXNd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unknownには、word2vecの全単語の平均のベクトルを運用する\n",
        "unk_vector = torch.from_numpy(np.mean(word2vec.vectors, axis=0))\n",
        "embedding_matrix = torch.zeros((len(vocab), 300))\n",
        "\n",
        "for i, word in enumerate(vocab.get_itos()):\n",
        "    if word in word2vec:\n",
        "        embedding_matrix[i] = torch.from_numpy(word2vec[word])\n",
        "    else:\n",
        "        embedding_matrix[i] = unk_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpPW-dAIOY1Q",
        "outputId": "bb8023f4-0f70-480a-94ff-261fd898ae83"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-890a7794e7c7>:7: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  embedding_matrix[i] = torch.from_numpy(word2vec[word])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデル"
      ],
      "metadata": {
        "id": "H1qFbFhSKC7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "Iyo-HwY0KE_A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, embedding_matrix=None, num_layers=1, rnn_type='LSTM', bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        # embedding layerの追加\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False) # embedding matrixで重みを初期化\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        input_size = embedding_dim\n",
        "\n",
        "        if rnn_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        else:\n",
        "            raise ValueError('Unsupported RNN type. Choose from [\"LSTM\", \"RNN\", \"GRU\", \"UGRNN\"]')\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*self.num_directions, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output_seq, _ = self.rnn(x)\n",
        "        output_seq = output_seq[:, -1, :]\n",
        "        # output_seq: [batch_size, seq_len, hidden_size*num_directions]\n",
        "        out = self.fc(output_seq)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "jE1xoN85OSH6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習ループ"
      ],
      "metadata": {
        "id": "I1kcq1dVXOpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (labels, sentences) in enumerate(train_loader):\n",
        "            sentences = sentences.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(sentences)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 検証データを使用して検証エラーを計算\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        total_samples = 0\n",
        "        total_correct = 0\n",
        "        for labels, sentences in val_loader:\n",
        "            sentences = sentences.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(sentences)\n",
        "            # loss計算\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # accuracy計算\n",
        "            _, predicted = torch.max(outputs, dim=-1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.numel()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = total_correct / total_samples\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "nUsanS0RXQcD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "num_classes = 4\n",
        "embedding_dim = 300\n",
        "hidden_size = 64\n",
        "output_size = num_classes\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "num_layers = 1\n",
        "\n",
        "# モデル作成\n",
        "model = Model(vocab_size, embedding_dim, hidden_size, output_size, embedding_matrix=embedding_matrix, num_layers=num_layers, rnn_type='LSTM', bidirectional=True)\n",
        "\n",
        "# 損失関数とOptimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "G4jqV0eUbNal"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSVGmoTEbTBK",
        "outputId": "b834ba73-017f-4fc0-e2bd-92df5c18a818"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Average Training Loss: 1.2460\n",
            "Val Loss: 0.9745, Val Accuracy: 0.4776\n",
            "Epoch 2/3, Average Training Loss: 0.7141\n",
            "Val Loss: 0.6346, Val Accuracy: 0.7287\n",
            "Epoch 3/3, Average Training Loss: 0.3777\n",
            "Val Loss: 0.3881, Val Accuracy: 0.8824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHx6Y4VQlxsr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}