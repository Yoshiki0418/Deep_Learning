{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND60/0WyLPDGb0CUIybyHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoshiki0418/Deep_Learning/blob/main/DL_Lecture3/advanced_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNNの更なる工夫"
      ],
      "metadata": {
        "id": "I880jvIWvYPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bidirectional RNN"
      ],
      "metadata": {
        "id": "XIv0ofcOvc4F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cbuLCOVzvM8j"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myRNN:\n",
        "    def __init__(self, input_size, hidden_size, bidirectional=False):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        init_range = 1.0/math.sqrt(hidden_size)\n",
        "\n",
        "        # 順方向の重みとバイアス\n",
        "        self.W_in = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "        self.W_h = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "        self.b_in = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "        self.b_h = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "\n",
        "        # 逆方向の重みとバイアス\n",
        "        self.W_in_backward = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "        self.W_h_backward = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "        self.b_in_backward = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "        self.b_h_backward = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
        "\n",
        "    def forward(self, input, h_0=None):\n",
        "        # input: [batch_size, seq_len, input_size]\n",
        "        self.input = input\n",
        "        self.h_0 = h_0\n",
        "        batch_size, self.seq_len, _ = input.size()\n",
        "\n",
        "        if h_0 is None:\n",
        "            self.h_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
        "\n",
        "        # 順方向の処理\n",
        "        h = self.h_0 # [1, batch_size, hidden_size]\n",
        "        outputs = []\n",
        "        for i in range(self.seq_len):\n",
        "            # [batch_size, hidden_size]\n",
        "            h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h)\n",
        "            outputs.append(h.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
        "        self.output_seq = torch.cat(outputs, dim=1)\n",
        "\n",
        "        # 逆方向の処理(双方向の場合)\n",
        "        if self.bidirectional:\n",
        "            h_backward = self.h_0\n",
        "            outputs_backward = []\n",
        "            for i in reversed(range(self.seq_len)):\n",
        "                # [batch_size, hidden_size]\n",
        "                h_backward = torch.tanh(input[:, i]@self.W_in_backward.T + self.b_in_backward + h_backward.squeeze(0)@self.W_h_backward.T + self.b_h_backward)\n",
        "                outputs_backward.append(h_backward.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
        "            # 順方向と逆方向の隠れ状態を同じステップで結合するようにする\n",
        "            outputs_backward = outputs_backward[::-1 ]\n",
        "            self.output_seq_backward = torch.cat(outputs_backward, dim=1)\n",
        "            self.output_seq = torch.cat((self.output_seq, self.output_seq_backward), dim=2)\n",
        "            # biRNNでは，h_n[0]に順方向の最後(t=T)の隠れ状態を保持し，h_n[1]に逆方向の最後(つまりシーケンス上ではt=1)の隠れ状態とする\n",
        "            h_n = torch.cat((h.unsqueeze(0), h_backward.unsqueeze(0)), dim=0) # [batch_size, hidden_size] -> [2, batch_size, hidden_size]\n",
        "        else:\n",
        "            h_n = h.unsqueeze(0)\n",
        "\n",
        "        return self.output_seq, h_n"
      ],
      "metadata": {
        "id": "yDIX1ExHvk8s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# BiRNNのテスト\n",
        "input_size = 10\n",
        "hidden_size = 3\n",
        "batch_size = 5\n",
        "seq_len = 5\n",
        "\n",
        "# サンプルのTensor\n",
        "input_tensor = torch.randn(batch_size, seq_len, input_size)\n",
        "birnn = myRNN(input_size, hidden_size, bidirectional=True)\n",
        "output_seq, h_n = birnn.forward(input_tensor)"
      ],
      "metadata": {
        "id": "yenJU1T_whKO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t=T\n",
        "(output_seq[:, -1, :hidden_size] == h_n[0]).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1aslVE2xZ_a",
        "outputId": "7a63023c-f6fe-42c3-a85d-71b86daf704b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# t=1\n",
        "(output_seq[:, 0, hidden_size:] == h_n[1]).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emwVEujbyJeU",
        "outputId": "2f4675d4-da3c-4eb8-f299-b3e59ad4deab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_n.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPl5CSGJyW_T",
        "outputId": "0b18ffc1-03f2-467b-d48e-097711144928"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PytorchのBidirectional"
      ],
      "metadata": {
        "id": "GjCLyaPiziZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, rnn_type='LSTM', bidirectional=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        if rnn_type == 'RNN':\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
        "        # elif rnn_type == 'UGRNN':\n",
        "        #     self.rnn = UGRNN(input_size, hidden_size, batch_first=True)\n",
        "        else:\n",
        "            raise ValueError('Unsupported RNN type. Choose from [\"LSTM\", \"RNN\", \"GRU\", \"UGRNN\"]')\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*self.num_directions, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output_seq, _ = self.rnn(x)\n",
        "        # output_seq: [batch_size, seq_len, hidden_size]\n",
        "        output_seq = output_seq[:, -1, :]\n",
        "        out = self.fc(output_seq)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4UkoavPazh1w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = nn.RNN(input_size, hidden_size, bidirectional=True)\n",
        "output_seq, hn = rnn(input_tensor)"
      ],
      "metadata": {
        "id": "5KwyGyME0Pk-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYB_LRTq0hiN",
        "outputId": "5069395b-2bc0-4b45-b5dd-6466030e3605"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_size = 3\n",
        "model = Model(input_size, hidden_size, output_size, rnn_type='LSTM', bidirectional=True)\n",
        "out = model(input_tensor)"
      ],
      "metadata": {
        "id": "3J_---Ra2wNX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzFxnWii2yP1",
        "outputId": "fb3125ee-6b9d-42a0-d26e-a9e6e698487e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_directions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgVfKtui20S0",
        "outputId": "ec473579-fdca-48b6-b226-0bc64e6f8ed4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep RNN"
      ],
      "metadata": {
        "id": "f1cNfDPi226P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers_list = [1, 2, 3]\n",
        "\n",
        "for num_layers in num_layers_list:\n",
        "    rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, bidirectional=True)\n",
        "    output_seq, h_n = rnn(input_tensor)\n",
        "\n",
        "    # 隠れ状態が増えていることを確認(双方向の場合2ずつ増える)\n",
        "    print(f\"Num Layers: {num_layers}\")\n",
        "    print(f\"Output Shape :{output_seq.shape}\")\n",
        "    print(f\"Last Hidden State Shape :{h_n.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-aQHPK322X9",
        "outputId": "d6a224e9-a125-4e56-f2cf-82dcce7e6fae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Layers: 1\n",
            "Output Shape :torch.Size([5, 5, 6])\n",
            "Last Hidden State Shape :torch.Size([2, 5, 3])\n",
            "Num Layers: 2\n",
            "Output Shape :torch.Size([5, 5, 6])\n",
            "Last Hidden State Shape :torch.Size([4, 5, 3])\n",
            "Num Layers: 3\n",
            "Output Shape :torch.Size([5, 5, 6])\n",
            "Last Hidden State Shape :torch.Size([6, 5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, rnn_type='LSTM', bidirectional=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        if rnn_type == 'RNN':\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        # elif rnn_type == 'UGRNN':\n",
        "        #     self.rnn = UGRNN(input_size, hidden_size, batch_first=True)\n",
        "        else:\n",
        "            raise ValueError('Unsupported RNN type. Choose from [\"LSTM\", \"RNN\", \"GRU\", \"UGRNN\"]')\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*self.num_directions, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output_seq, _ = self.rnn(x)\n",
        "        # output_seq: [batch_size, seq_len, hidden_size]\n",
        "        output_seq = output_seq[:, -1, :]\n",
        "        out = self.fc(output_seq)\n",
        "        return out"
      ],
      "metadata": {
        "id": "yJ_Bs0RM4BIA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_size, hidden_size, output_size, num_layers=2, rnn_type='LSTM', bidirectional=True)\n",
        "out = model(input_tensor)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNF0Qt0F4Jbz",
        "outputId": "084e5575-075b-496a-9b90-740fff05b8e2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n"
          ]
        }
      ]
    }
  ]
}